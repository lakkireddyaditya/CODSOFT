import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# Load dataset (Example: Using IAM Dataset - should be preprocessed accordingly)
# Assuming `text` is a large string containing handwritten text
with open("handwritten_text.txt", "r", encoding="utf-8") as file:
    text = file.read().lower()

# Character mapping
chars = sorted(list(set(text)))
char_to_idx = {c: i for i, c in enumerate(chars)}
idx_to_char = {i: c for i, c in enumerate(chars)}

# Prepare training sequences
sequence_length = 40
step = 3
sentences = []
next_chars = []
for i in range(0, len(text) - sequence_length, step):
    sentences.append(text[i: i + sequence_length])
    next_chars.append(text[i + sequence_length])

X = np.zeros((len(sentences), sequence_length, len(chars)), dtype=np.bool_)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)

for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        X[i, t, char_to_idx[char]] = 1
    y[i, char_to_idx[next_chars[i]]] = 1

# Build the model
model = Sequential([
    LSTM(128, input_shape=(sequence_length, len(chars)), return_sequences=True),
    LSTM(128),
    Dense(len(chars), activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam')

# Train the model
model.fit(X, y, batch_size=128, epochs=20)

# Text generation function
def generate_text(seed_text, length=200):
    generated = seed_text
    for _ in range(length):
        x_pred = np.zeros((1, sequence_length, len(chars)))
        for t, char in enumerate(seed_text):
            x_pred[0, t, char_to_idx[char]] = 1
        
        preds = model.predict(x_pred, verbose=0)[0]
        next_char = idx_to_char[np.argmax(preds)]
        generated += next_char
        seed_text = seed_text[1:] + next_char
    return generated

# Example usage
seed = "the quick brown fox jumps over the lazy dog"
print(generate_text(seed, length=300))
